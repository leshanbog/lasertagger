{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "    r'C:\\Users\\leshanbog\\Documents\\model\\bert\\rubert_cased_L-12_H-768_A-12_v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ria_enum(input_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as r:\n",
    "        for line in r:\n",
    "            data = json.loads(line.strip())\n",
    "            title = data[\"title\"]\n",
    "            text = data[\"text\"]\n",
    "            clean_text = BeautifulSoup(text, 'html.parser').text.replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "            if len(clean_text) < 10 or not title:\n",
    "                continue\n",
    "            yield clean_text, title\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenta_enum(input_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as r:\n",
    "        reader = csv.reader(r, delimiter=\",\", quotechar='\"')\n",
    "        header = next(reader)\n",
    "        assert header[1] == \"title\"\n",
    "        assert header[2] == \"text\"\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            title, text = row[1], row[2]\n",
    "            if not title or not text or len(text) < 10:\n",
    "                continue\n",
    "            text = text.lower().replace(\"\\xa0\", \" \")\n",
    "            title = title.lower().replace(\"\\xa0\", \" \")\n",
    "            yield text, title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ria_train = r'C:\\Users\\leshanbog\\Documents\\dataset\\lenta\\lenta-ru-news.val.csv'\n",
    "ria_train_subword = r'C:\\Users\\leshanbog\\Documents\\dataset\\lenta\\lenta_val.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 documents\n",
      "Processed 1000 documents\n",
      "Processed 2000 documents\n",
      "Processed 3000 documents\n",
      "Processed 4000 documents\n",
      "Processed 5000 documents\n",
      "Processed 6000 documents\n",
      "Processed 7000 documents\n",
      "Processed 8000 documents\n",
      "Processed 9000 documents\n",
      "Processed 10000 documents\n",
      "Processed 11000 documents\n",
      "Processed 12000 documents\n",
      "Processed 13000 documents\n",
      "Processed 14000 documents\n",
      "Processed 15000 documents\n",
      "Processed 16000 documents\n",
      "Processed 17000 documents\n",
      "Processed 18000 documents\n",
      "Processed 19000 documents\n",
      "Processed 20000 documents\n",
      "Processed 21000 documents\n",
      "Processed 22000 documents\n",
      "Processed 23000 documents\n",
      "Processed 24000 documents\n",
      "Processed 25000 documents\n",
      "Processed 26000 documents\n",
      "Processed 27000 documents\n",
      "Processed 28000 documents\n",
      "Processed 29000 documents\n",
      "Processed 30000 documents\n",
      "Processed 31000 documents\n",
      "Processed 32000 documents\n",
      "Processed 33000 documents\n",
      "Processed 34000 documents\n",
      "Processed 35000 documents\n",
      "Processed 36000 documents\n",
      "Processed 37000 documents\n",
      "Processed 38000 documents\n",
      "Processed 39000 documents\n",
      "Processed 40000 documents\n",
      "Processed 41000 documents\n",
      "Processed 42000 documents\n",
      "Processed 43000 documents\n",
      "Processed 44000 documents\n",
      "Processed 45000 documents\n",
      "Processed 46000 documents\n",
      "Processed 47000 documents\n",
      "Processed 48000 documents\n",
      "Processed 49000 documents\n",
      "Processed 50000 documents\n",
      "Processed 51000 documents\n",
      "Processed 52000 documents\n",
      "Processed 53000 documents\n",
      "Processed 54000 documents\n",
      "Processed 55000 documents\n",
      "Processed 56000 documents\n",
      "Processed 57000 documents\n",
      "Processed 58000 documents\n",
      "Processed 59000 documents\n",
      "Processed 60000 documents\n",
      "Processed 61000 documents\n",
      "Processed 62000 documents\n",
      "Processed 63000 documents\n",
      "Processed 64000 documents\n",
      "Processed 65000 documents\n",
      "Processed 66000 documents\n",
      "Processed 67000 documents\n",
      "Processed 68000 documents\n",
      "Processed 69000 documents\n",
      "Processed 70000 documents\n",
      "Processed 71000 documents\n",
      "Processed 72000 documents\n",
      "Processed 73000 documents\n",
      "Processed 74000 documents\n",
      "Processed 75000 documents\n"
     ]
    }
   ],
   "source": [
    "with open(ria_train_subword, 'w', encoding='utf-8') as f:\n",
    "    for j, (text, title) in enumerate(lenta_enum(ria_train)):\n",
    "        if j % 1000 == 0:\n",
    "            print('Processed {} documents'.format(j))\n",
    "            \n",
    "        f.write(' '.join(tokenizer.tokenize(text)) + '\\t')\n",
    "        f.write(' '.join(tokenizer.tokenize(title)) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
